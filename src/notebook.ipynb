{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openml\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('data_list.pkl', 'rb') as f:\n",
    "    data_list = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small datasets:\n",
    "- 37: diabetes\n",
    "- 1462: banknote-authentication\n",
    "- 871: pollen\n",
    "\n",
    "Large datasets:\n",
    "- 752: puma32H\n",
    "- 1120: MagicTelescope\n",
    "- 23512: higgs\n",
    "- 23517: numerai28.6\n",
    "- 979: waveform-5000\n",
    "- 1487: ozone-level-8hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(id):\n",
    "    dataset = openml.datasets.get_dataset(id)\n",
    "    df, _, _, _ = dataset.get_data(dataset_format=\"dataframe\")\n",
    "    numerical_cols = df.select_dtypes(include='number').columns\n",
    "    target_col = df.select_dtypes(exclude='number').columns\n",
    "    X = df[numerical_cols].to_numpy()\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(df[target_col])\n",
    "    return X, y\n",
    "\n",
    "def list_data(id_list):\n",
    "    data_list = []\n",
    "    for id in id_list:\n",
    "        data_list.append(read_data(id))\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = [37, 1462, 871, 752, 1120, 23512, 23517, 979, 1487] #small datasets first\n",
    "data_list = list_data(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 has no missing values.\n",
      "Dataset 2 has no missing values.\n",
      "Dataset 3 has no missing values.\n",
      "Dataset 4 has no missing values.\n",
      "Dataset 5 has no missing values.\n",
      "Dataset 6 has missing values:\n",
      "Missing values in X: 9\n",
      "Missing values in y: 0\n",
      "Dataset 7 has no missing values.\n",
      "Dataset 8 has no missing values.\n",
      "Dataset 9 has no missing values.\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(data_list):\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y)\n",
    "    missing_X = X.isnull().sum().sum()\n",
    "    missing_y = y.isnull().sum().sum()\n",
    "    \n",
    "    if missing_X > 0 or missing_y > 0:\n",
    "        print(f\"Dataset {i+1} has missing values:\")\n",
    "        print(f\"Missing values in X: {missing_X}\")\n",
    "        print(f\"Missing values in y: {missing_y}\")\n",
    "        X = X.fillna(X.mean())\n",
    "        y = y.fillna(y.mean())\n",
    "        data_list[i] = (X.to_numpy(), (y.to_numpy()).flatten())\n",
    "    else:\n",
    "        print(f\"Dataset {i+1} has no missing values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols(df, threshold=0.8):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    df.drop(columns=to_drop, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dataset 1 for highly correlated columns...\n",
      "0 highly correlated columns removed.\n",
      "Checking dataset 2 for highly correlated columns...\n",
      "0 highly correlated columns removed.\n",
      "Checking dataset 3 for highly correlated columns...\n",
      "1 highly correlated columns removed.\n",
      "Checking dataset 4 for highly correlated columns...\n",
      "0 highly correlated columns removed.\n",
      "Checking dataset 5 for highly correlated columns...\n",
      "2 highly correlated columns removed.\n",
      "Checking dataset 6 for highly correlated columns...\n",
      "1 highly correlated columns removed.\n",
      "Checking dataset 7 for highly correlated columns...\n",
      "8 highly correlated columns removed.\n",
      "Checking dataset 8 for highly correlated columns...\n",
      "0 highly correlated columns removed.\n",
      "Checking dataset 9 for highly correlated columns...\n",
      "57 highly correlated columns removed.\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(data_list):\n",
    "    print(f\"Checking dataset {i+1} for highly correlated columns...\")\n",
    "    X = pd.DataFrame(X)\n",
    "    y = pd.DataFrame(y, columns=['y'])\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "\n",
    "    X_cleaned = remove_cols(data.drop(columns=['y']), threshold=0.8)\n",
    "    y_cleaned = data['y']\n",
    "    \n",
    "    data_list[i] = (X_cleaned.to_numpy(), (y_cleaned.to_numpy()).flatten())\n",
    "    print(f\"{X.shape[1] - X_cleaned.shape[1]} highly correlated columns removed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
